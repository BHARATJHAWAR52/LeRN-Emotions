{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "# !pip install seaborn\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from itertools import cycle\n",
    "import soundfile\n",
    "import os, pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FREQUENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTENSITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'D:\\\\RAVDESS Emotional speech audio\\\\archive (5)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "        contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(audio), sr=sample_rate)\n",
    "        \n",
    "        features = np.hstack((\n",
    "            np.mean(mfccs.T, axis=0),\n",
    "            np.mean(chroma.T, axis=0),\n",
    "            np.mean(mel.T, axis=0),\n",
    "            np.mean(contrast.T, axis=0),\n",
    "            np.mean(tonnetz.T, axis=0)\n",
    "        ))\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "    '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list to store the extracted features and corresponding labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the dataset\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            extracted_features = extract_features(file_path)\n",
    "            \n",
    "            if extracted_features is not None:\n",
    "                features.append(extracted_features)\n",
    "                # Extract label from the file name\n",
    "                parts = file.split('-')\n",
    "                emotion = emotion_map[parts[2]]\n",
    "                labels.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0          1         2          3         4          5         6  \\\n",
      "0 -726.217224  68.541420  3.293398  12.205300  5.510278  13.667408 -2.983828   \n",
      "1 -719.128296  70.201569  1.168397  13.122541  7.836950  14.411290 -4.111360   \n",
      "2 -714.995728  69.689346  3.924564  11.924190  6.421723  11.011614 -2.878103   \n",
      "3 -710.975281  67.564880  5.782241  13.230726  6.190845  12.628252 -1.675169   \n",
      "4 -759.921753  75.783524  6.023605  14.557394  6.454187  14.631508 -3.004551   \n",
      "\n",
      "          7         8         9  ...        157        158        159  \\\n",
      "0  3.098029 -3.310813 -1.564384  ...  14.896630  15.938653  17.161146   \n",
      "1  4.468973 -3.539367 -3.658607  ...  14.797068  16.028111  17.303416   \n",
      "2  4.509558 -4.476109 -2.671549  ...  15.356175  16.092042  17.107516   \n",
      "3  5.657494 -4.950634 -3.477545  ...  15.625618  15.486327  17.372365   \n",
      "4  4.620970 -5.200016 -0.707430  ...  15.277864  15.372324  16.627257   \n",
      "\n",
      "        160       161       162       163       164       165    label  \n",
      "0 -0.041720  0.033167 -0.046392 -0.050864  0.012085  0.012860  neutral  \n",
      "1 -0.072259  0.040765 -0.058097 -0.065337  0.026146  0.005308  neutral  \n",
      "2 -0.029248  0.009355  0.008024  0.003081  0.009819  0.024897  neutral  \n",
      "3 -0.050754  0.018956  0.011561 -0.040490  0.010340  0.009326  neutral  \n",
      "4 -0.077921  0.020432  0.007521 -0.108841  0.025209  0.010315     calm  \n",
      "\n",
      "[5 rows x 167 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(features)\n",
    "df['label'] = labels\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('ravdess_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "def play_audio(file_path):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        data, sample_rate = sf.read(file_path)\n",
    "        # Play the audio file\n",
    "        sd.play(data, sample_rate)\n",
    "        # Wait until the file is done playing\n",
    "        sd.wait()\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing {file_path}: {e}\")\n",
    "\n",
    "# Example: Play a specific audio file\n",
    "example_file_path = os.path.join(dataset_path, 'Actor_01', '03-01-01-01-01-01-01.wav')\n",
    "play_audio(example_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-726.217224</td>\n",
       "      <td>68.541420</td>\n",
       "      <td>3.293398</td>\n",
       "      <td>12.205300</td>\n",
       "      <td>5.510278</td>\n",
       "      <td>13.667408</td>\n",
       "      <td>-2.983828</td>\n",
       "      <td>3.098029</td>\n",
       "      <td>-3.310813</td>\n",
       "      <td>-1.564384</td>\n",
       "      <td>...</td>\n",
       "      <td>14.896630</td>\n",
       "      <td>15.938653</td>\n",
       "      <td>17.161146</td>\n",
       "      <td>-0.041720</td>\n",
       "      <td>0.033167</td>\n",
       "      <td>-0.046392</td>\n",
       "      <td>-0.050864</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-719.128296</td>\n",
       "      <td>70.201569</td>\n",
       "      <td>1.168397</td>\n",
       "      <td>13.122541</td>\n",
       "      <td>7.836950</td>\n",
       "      <td>14.411290</td>\n",
       "      <td>-4.111360</td>\n",
       "      <td>4.468973</td>\n",
       "      <td>-3.539367</td>\n",
       "      <td>-3.658607</td>\n",
       "      <td>...</td>\n",
       "      <td>14.797068</td>\n",
       "      <td>16.028111</td>\n",
       "      <td>17.303416</td>\n",
       "      <td>-0.072259</td>\n",
       "      <td>0.040765</td>\n",
       "      <td>-0.058097</td>\n",
       "      <td>-0.065337</td>\n",
       "      <td>0.026146</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-714.995728</td>\n",
       "      <td>69.689346</td>\n",
       "      <td>3.924564</td>\n",
       "      <td>11.924190</td>\n",
       "      <td>6.421723</td>\n",
       "      <td>11.011614</td>\n",
       "      <td>-2.878103</td>\n",
       "      <td>4.509558</td>\n",
       "      <td>-4.476109</td>\n",
       "      <td>-2.671549</td>\n",
       "      <td>...</td>\n",
       "      <td>15.356175</td>\n",
       "      <td>16.092042</td>\n",
       "      <td>17.107516</td>\n",
       "      <td>-0.029248</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.024897</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-710.975281</td>\n",
       "      <td>67.564880</td>\n",
       "      <td>5.782241</td>\n",
       "      <td>13.230726</td>\n",
       "      <td>6.190845</td>\n",
       "      <td>12.628252</td>\n",
       "      <td>-1.675169</td>\n",
       "      <td>5.657494</td>\n",
       "      <td>-4.950634</td>\n",
       "      <td>-3.477545</td>\n",
       "      <td>...</td>\n",
       "      <td>15.625618</td>\n",
       "      <td>15.486327</td>\n",
       "      <td>17.372365</td>\n",
       "      <td>-0.050754</td>\n",
       "      <td>0.018956</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>-0.040490</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-759.921753</td>\n",
       "      <td>75.783524</td>\n",
       "      <td>6.023605</td>\n",
       "      <td>14.557394</td>\n",
       "      <td>6.454187</td>\n",
       "      <td>14.631508</td>\n",
       "      <td>-3.004551</td>\n",
       "      <td>4.620970</td>\n",
       "      <td>-5.200016</td>\n",
       "      <td>-0.707430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.277864</td>\n",
       "      <td>15.372324</td>\n",
       "      <td>16.627257</td>\n",
       "      <td>-0.077921</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>-0.108841</td>\n",
       "      <td>0.025209</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>-616.322449</td>\n",
       "      <td>45.899368</td>\n",
       "      <td>-20.175966</td>\n",
       "      <td>3.753582</td>\n",
       "      <td>-11.131477</td>\n",
       "      <td>-3.964839</td>\n",
       "      <td>-14.135321</td>\n",
       "      <td>-4.771224</td>\n",
       "      <td>-15.621428</td>\n",
       "      <td>-8.477671</td>\n",
       "      <td>...</td>\n",
       "      <td>17.711438</td>\n",
       "      <td>16.802803</td>\n",
       "      <td>20.631427</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>-0.012989</td>\n",
       "      <td>0.029897</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>-553.992004</td>\n",
       "      <td>56.614849</td>\n",
       "      <td>-14.907667</td>\n",
       "      <td>2.665701</td>\n",
       "      <td>-13.776782</td>\n",
       "      <td>-4.072508</td>\n",
       "      <td>-17.319796</td>\n",
       "      <td>-5.079650</td>\n",
       "      <td>-10.142247</td>\n",
       "      <td>-8.829944</td>\n",
       "      <td>...</td>\n",
       "      <td>16.785011</td>\n",
       "      <td>17.009239</td>\n",
       "      <td>21.708454</td>\n",
       "      <td>-0.019153</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>-0.000938</td>\n",
       "      <td>-0.008314</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>-575.845764</td>\n",
       "      <td>53.281605</td>\n",
       "      <td>-21.947104</td>\n",
       "      <td>5.056113</td>\n",
       "      <td>-12.553356</td>\n",
       "      <td>-2.494527</td>\n",
       "      <td>-20.614611</td>\n",
       "      <td>-6.246452</td>\n",
       "      <td>-10.795346</td>\n",
       "      <td>-8.800463</td>\n",
       "      <td>...</td>\n",
       "      <td>16.639615</td>\n",
       "      <td>17.078960</td>\n",
       "      <td>21.849838</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>0.024669</td>\n",
       "      <td>-0.043076</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>-522.466980</td>\n",
       "      <td>43.700798</td>\n",
       "      <td>-14.606612</td>\n",
       "      <td>12.619474</td>\n",
       "      <td>-11.496836</td>\n",
       "      <td>1.743054</td>\n",
       "      <td>-13.268276</td>\n",
       "      <td>0.747497</td>\n",
       "      <td>-13.840753</td>\n",
       "      <td>-2.510027</td>\n",
       "      <td>...</td>\n",
       "      <td>17.729482</td>\n",
       "      <td>16.652768</td>\n",
       "      <td>23.641165</td>\n",
       "      <td>-0.023364</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>-0.052340</td>\n",
       "      <td>-0.029746</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>-536.690430</td>\n",
       "      <td>43.285828</td>\n",
       "      <td>-9.279314</td>\n",
       "      <td>9.257221</td>\n",
       "      <td>-10.542926</td>\n",
       "      <td>3.866606</td>\n",
       "      <td>-11.568683</td>\n",
       "      <td>-4.174040</td>\n",
       "      <td>-9.066223</td>\n",
       "      <td>-4.903262</td>\n",
       "      <td>...</td>\n",
       "      <td>17.028849</td>\n",
       "      <td>16.485048</td>\n",
       "      <td>23.206617</td>\n",
       "      <td>-0.031517</td>\n",
       "      <td>0.044979</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>-0.024440</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>surprised</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "0    -726.217224  68.541420   3.293398  12.205300   5.510278  13.667408   \n",
       "1    -719.128296  70.201569   1.168397  13.122541   7.836950  14.411290   \n",
       "2    -714.995728  69.689346   3.924564  11.924190   6.421723  11.011614   \n",
       "3    -710.975281  67.564880   5.782241  13.230726   6.190845  12.628252   \n",
       "4    -759.921753  75.783524   6.023605  14.557394   6.454187  14.631508   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "2875 -616.322449  45.899368 -20.175966   3.753582 -11.131477  -3.964839   \n",
       "2876 -553.992004  56.614849 -14.907667   2.665701 -13.776782  -4.072508   \n",
       "2877 -575.845764  53.281605 -21.947104   5.056113 -12.553356  -2.494527   \n",
       "2878 -522.466980  43.700798 -14.606612  12.619474 -11.496836   1.743054   \n",
       "2879 -536.690430  43.285828  -9.279314   9.257221 -10.542926   3.866606   \n",
       "\n",
       "              6         7          8         9  ...        157        158  \\\n",
       "0     -2.983828  3.098029  -3.310813 -1.564384  ...  14.896630  15.938653   \n",
       "1     -4.111360  4.468973  -3.539367 -3.658607  ...  14.797068  16.028111   \n",
       "2     -2.878103  4.509558  -4.476109 -2.671549  ...  15.356175  16.092042   \n",
       "3     -1.675169  5.657494  -4.950634 -3.477545  ...  15.625618  15.486327   \n",
       "4     -3.004551  4.620970  -5.200016 -0.707430  ...  15.277864  15.372324   \n",
       "...         ...       ...        ...       ...  ...        ...        ...   \n",
       "2875 -14.135321 -4.771224 -15.621428 -8.477671  ...  17.711438  16.802803   \n",
       "2876 -17.319796 -5.079650 -10.142247 -8.829944  ...  16.785011  17.009239   \n",
       "2877 -20.614611 -6.246452 -10.795346 -8.800463  ...  16.639615  17.078960   \n",
       "2878 -13.268276  0.747497 -13.840753 -2.510027  ...  17.729482  16.652768   \n",
       "2879 -11.568683 -4.174040  -9.066223 -4.903262  ...  17.028849  16.485048   \n",
       "\n",
       "            159       160       161       162       163       164       165  \\\n",
       "0     17.161146 -0.041720  0.033167 -0.046392 -0.050864  0.012085  0.012860   \n",
       "1     17.303416 -0.072259  0.040765 -0.058097 -0.065337  0.026146  0.005308   \n",
       "2     17.107516 -0.029248  0.009355  0.008024  0.003081  0.009819  0.024897   \n",
       "3     17.372365 -0.050754  0.018956  0.011561 -0.040490  0.010340  0.009326   \n",
       "4     16.627257 -0.077921  0.020432  0.007521 -0.108841  0.025209  0.010315   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "2875  20.631427  0.011145  0.010914 -0.012989  0.029897  0.004431  0.016376   \n",
       "2876  21.708454 -0.019153  0.007158 -0.000938 -0.008314  0.013664 -0.000264   \n",
       "2877  21.849838 -0.018989  0.024669 -0.043076  0.009058  0.011479  0.010839   \n",
       "2878  23.641165 -0.023364  0.022528 -0.052340 -0.029746  0.012789 -0.000936   \n",
       "2879  23.206617 -0.031517  0.044979  0.005631 -0.024440  0.004284  0.005040   \n",
       "\n",
       "          label  \n",
       "0       neutral  \n",
       "1       neutral  \n",
       "2       neutral  \n",
       "3       neutral  \n",
       "4          calm  \n",
       "...         ...  \n",
       "2875  surprised  \n",
       "2876  surprised  \n",
       "2877  surprised  \n",
       "2878  surprised  \n",
       "2879  surprised  \n",
       "\n",
       "[2880 rows x 167 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('ravdess_features.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data['label'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "X_reshaped = X_normalized.reshape(X_normalized.shape[0], X_normalized.shape[1], 1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BHARAT JHAWAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 1), activation='relu', input_shape=(X_train.shape[1], 1, 1),padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (2, 1), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(np.unique(y_encoded)), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.2035 - loss: 1.9978 - val_accuracy: 0.3073 - val_loss: 1.7468\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3186 - loss: 1.7293 - val_accuracy: 0.3924 - val_loss: 1.6191\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3853 - loss: 1.6248 - val_accuracy: 0.4462 - val_loss: 1.5156\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4006 - loss: 1.5675 - val_accuracy: 0.4740 - val_loss: 1.4480\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4331 - loss: 1.4836 - val_accuracy: 0.4861 - val_loss: 1.3861\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4504 - loss: 1.4500 - val_accuracy: 0.5243 - val_loss: 1.3224\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5037 - loss: 1.3391 - val_accuracy: 0.5260 - val_loss: 1.3023\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4963 - loss: 1.3515 - val_accuracy: 0.5434 - val_loss: 1.2452\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4989 - loss: 1.3143 - val_accuracy: 0.5868 - val_loss: 1.2261\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5496 - loss: 1.2374 - val_accuracy: 0.5729 - val_loss: 1.1741\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5654 - loss: 1.1805 - val_accuracy: 0.5694 - val_loss: 1.1270\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5705 - loss: 1.2038 - val_accuracy: 0.5868 - val_loss: 1.1182\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5612 - loss: 1.1668 - val_accuracy: 0.6233 - val_loss: 1.0614\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5819 - loss: 1.1243 - val_accuracy: 0.6319 - val_loss: 1.0270\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6104 - loss: 1.0729 - val_accuracy: 0.6476 - val_loss: 1.0110\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6067 - loss: 1.0927 - val_accuracy: 0.6510 - val_loss: 0.9899\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6151 - loss: 1.0259 - val_accuracy: 0.6944 - val_loss: 0.9383\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.9933 - val_accuracy: 0.6719 - val_loss: 0.9070\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6463 - loss: 0.9641 - val_accuracy: 0.7188 - val_loss: 0.8950\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6615 - loss: 0.9234 - val_accuracy: 0.6910 - val_loss: 0.8627\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6403 - loss: 0.9522 - val_accuracy: 0.7118 - val_loss: 0.8545\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6689 - loss: 0.8925 - val_accuracy: 0.7309 - val_loss: 0.8250\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6911 - loss: 0.8742 - val_accuracy: 0.7413 - val_loss: 0.7768\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6884 - loss: 0.8692 - val_accuracy: 0.7587 - val_loss: 0.7560\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6916 - loss: 0.8412 - val_accuracy: 0.7622 - val_loss: 0.7371\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6842 - loss: 0.8615 - val_accuracy: 0.7205 - val_loss: 0.7619\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7134 - loss: 0.8094 - val_accuracy: 0.7639 - val_loss: 0.7133\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6885 - loss: 0.8246 - val_accuracy: 0.7517 - val_loss: 0.7201\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7301 - loss: 0.7481 - val_accuracy: 0.7778 - val_loss: 0.6863\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6925 - loss: 0.8372 - val_accuracy: 0.7951 - val_loss: 0.6615\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7276 - loss: 0.7496 - val_accuracy: 0.8056 - val_loss: 0.6301\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7454 - loss: 0.7146 - val_accuracy: 0.7847 - val_loss: 0.6383\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7618 - loss: 0.7231 - val_accuracy: 0.8229 - val_loss: 0.6175\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7441 - loss: 0.6925 - val_accuracy: 0.8056 - val_loss: 0.5838\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7523 - loss: 0.6969 - val_accuracy: 0.8264 - val_loss: 0.5899\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7429 - loss: 0.6934 - val_accuracy: 0.8351 - val_loss: 0.5530\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7639 - loss: 0.6521 - val_accuracy: 0.8264 - val_loss: 0.5564\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7689 - loss: 0.6338 - val_accuracy: 0.8438 - val_loss: 0.5414\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7781 - loss: 0.5960 - val_accuracy: 0.8177 - val_loss: 0.5528\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7612 - loss: 0.6518 - val_accuracy: 0.8420 - val_loss: 0.5055\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7791 - loss: 0.6200 - val_accuracy: 0.8663 - val_loss: 0.5138\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7598 - loss: 0.6334 - val_accuracy: 0.8455 - val_loss: 0.5115\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7864 - loss: 0.5926 - val_accuracy: 0.8611 - val_loss: 0.5089\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7908 - loss: 0.5702 - val_accuracy: 0.8611 - val_loss: 0.4897\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8022 - loss: 0.5530 - val_accuracy: 0.8715 - val_loss: 0.4634\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 0.5278 - val_accuracy: 0.8507 - val_loss: 0.4698\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8044 - loss: 0.5276 - val_accuracy: 0.8698 - val_loss: 0.4553\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8030 - loss: 0.5283 - val_accuracy: 0.8854 - val_loss: 0.4753\n",
      "Epoch 49/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8082 - loss: 0.5341 - val_accuracy: 0.8872 - val_loss: 0.4617\n",
      "Epoch 50/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8085 - loss: 0.5498 - val_accuracy: 0.8802 - val_loss: 0.4772\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.4683\n",
      "Test Accuracy: 88.02%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "model.save('ravdess_emotion_model_cnn.h5')\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming model.predict(X_test) gives predictions in the shape (num_samples, num_classes)\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "# Decode predictions and true labels using inverse_transform\n",
    "y_pred = label_encoder.inverse_transform(np.argmax(pred_test, axis=1))\n",
    "y_true = label_encoder.inverse_transform(np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Predicted Labels Actual Labels\n",
      "0          disgust       disgust\n",
      "1            happy         happy\n",
      "2          disgust       fearful\n",
      "3          fearful       fearful\n",
      "4            happy         happy\n",
      "5        surprised     surprised\n",
      "6          disgust       disgust\n",
      "7            angry         angry\n",
      "8          disgust       disgust\n",
      "9          neutral       neutral\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to compare predicted and actual labels\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred\n",
    "df['Actual Labels'] = y_true\n",
    "\n",
    "# Check the first 10 rows\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
